{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Kn2RS0NcIMkt"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dDMP7W7dFwUM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1Mj9SDpZFs5X"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rUxszBf1GJap"
   },
   "outputs": [],
   "source": [
    "train['sentiment_subjectivity'] = train['description'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xweS7ihcMIVE"
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    blob = TextBlob(doc)\n",
    "    words = TextBlob(doc).words\n",
    "    #words = TextBlob(words.correct()).lemmatize()\n",
    "\n",
    "    return [word.lemmatize() for word in words]\n",
    "    #return words.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize2(doc):\n",
    "    return [doc for doc in nlp(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4/16/1993',\n",
       " 'helloo',\n",
       " 'there',\n",
       " 'my',\n",
       " 'goood',\n",
       " 'fellow',\n",
       " 'and',\n",
       " 'friend',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'John',\n",
       " \"'s\",\n",
       " 'wolf',\n",
       " 'f2',\n",
       " 'n/ef',\n",
       " '\\x08b',\n",
       " 'f12',\n",
       " 'f142',\n",
       " '122',\n",
       " 'p3n1s']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"4/16/1993 helloo there my goood fellowss and friends I'm John's wolves f2$#/n/ef \\bb [f12] f142 122 p3n1s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4/16/1993,\n",
       " helloo,\n",
       " the,\n",
       " there,\n",
       " my,\n",
       " goood,\n",
       " fellowss,\n",
       " and,\n",
       " friends,\n",
       " I,\n",
       " 'm,\n",
       " John,\n",
       " 's,\n",
       " wolves,\n",
       " f2$#/n,\n",
       " /,\n",
       " ef,\n",
       " \bb,\n",
       " [,\n",
       " f12,\n",
       " ],\n",
       " f142,\n",
       " 122,\n",
       " p3n1s]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize2(\"4/16/1993 helloo the there my goood fellowss and friends I'm John's wolves f2$#/n/ef \\bb [f12] f142 122 p3n1s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Sometimes, when, whisky, is, batched, a, few,...\n",
       "1       [An, uncommon, exclusive, bottling, of, a, 6, ...\n",
       "2       [This, release, is, a, port, version, of, Amru...\n",
       "3       [This, 41, year, old, single, cask, wa, aged, ...\n",
       "4       [Quite, herbal, on, the, nose, with, aroma, of...\n",
       "                              ...                        \n",
       "4082    [What, lie, beneath, the, surface, of, Dewar, ...\n",
       "4083    [After, 6, to, 7, year, of, maturation, in, bo...\n",
       "4084    [Bright, delicate, and, approachable, While, n...\n",
       "4085    [I, ’, m, calling, this, the, pitmaster, ’, s,...\n",
       "4086    [Spicy, sultana, greengage, plum, toffee, and,...\n",
       "Name: description, Length: 4087, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    \"Returns a 300 word term-doc matrix\"\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "pl3V2hQEIRfT"
   },
   "outputs": [],
   "source": [
    "extend_stop_words = [' ', '', ',', '’ s', 's', 'd', 'doe', 'ha', 'le', 'll', 'm', 'n', 't', 'u', 've', 'wa', '‘', '’']\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union(extend_stop_words)\n",
    "\n",
    "vect = TfidfVectorizer(stop_words=STOP_WORDS, tokenizer=tokenize, ngram_range=(1,2), sublinear_tf=True, \n",
    "                       min_df=.01, max_features=10000, max_df=.75)\n",
    "#clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=375, max_depth=130)\n",
    "#clf = XGBClassifier(n_estimators=375, max_depth=130)\n",
    "\n",
    "pipe = Pipeline([\n",
    "                 ('vect', vect), ('clf', clf)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "jCO-QAAxJ13u"
   },
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(train['description'])\n",
    "dtm = pd.DataFrame(data=dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainnn = vect.fit_transform(train['description']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOf_6tNGJ3VD",
    "outputId": "c9629688-1e6d-4b67-a1a8-9c52d3c2a4fc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oak               85.344731\n",
       "fruit             83.688925\n",
       "whisky            82.388973\n",
       "finish            82.203024\n",
       "note              81.800809\n",
       "                    ...    \n",
       "old integrates     0.152793\n",
       "old feel 17        0.152793\n",
       "old duty free      0.152793\n",
       "old duty           0.152793\n",
       "portfolio 17       0.152793\n",
       "Length: 30000, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCRQIfDdIVJc",
    "outputId": "434bf50f-5e6b-47a8-e50f-d2fd9accc594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    8.5s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(max_df=0.89,\n",
       "                                                        max_features=10000,\n",
       "                                                        min_df=0.01,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        stop_words={'', ' ',\n",
       "                                                                    \"'d\", \"'ll\",\n",
       "                                                                    \"'m\", \"'re\",\n",
       "                                                                    \"'s\", \"'ve\",\n",
       "                                                                    ',', 'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'across',\n",
       "                                                                    'after',\n",
       "                                                                    'afterwards',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'all',\n",
       "                                                                    'almost',\n",
       "                                                                    'alone',\n",
       "                                                                    'along',\n",
       "                                                                    'already',\n",
       "                                                                    'also',\n",
       "                                                                    'although',\n",
       "                                                                    'always',\n",
       "                                                                    'am',\n",
       "                                                                    'among',\n",
       "                                                                    'amongst',\n",
       "                                                                    'amount...\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vect__stop_words': ('english',\n",
       "                                              {'', ' ', \"'d\", \"'ll\", \"'m\",\n",
       "                                               \"'re\", \"'s\", \"'ve\", ',', 'a',\n",
       "                                               'about', 'above', 'across',\n",
       "                                               'after', 'afterwards', 'again',\n",
       "                                               'against', 'all', 'almost',\n",
       "                                               'alone', 'along', 'already',\n",
       "                                               'also', 'although', 'always',\n",
       "                                               'am', 'among', 'amongst',\n",
       "                                               'amount', 'an', ...}),\n",
       "                         'vect__tokenizer': ('word',\n",
       "                                             <function tokenize at 0x0000018D98432AF0>)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train['ratingCategory']\n",
    "features = train.drop(columns=['ratingCategory', 'id'])\n",
    "features = train['description']\n",
    "\n",
    "parameters = {\n",
    "    'vect__min_df': (.75, .85),\n",
    "    'vect__min_df': (.01, .05),\n",
    "    'clf__alpha': (1e-2, 1e-3)\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'vect__tokenizer': ('word', tokenize),\n",
    "    'vect__stop_words':('english', STOP_WORDS)\n",
    "    #'vect__max_df': (.7, .75, .8),\n",
    "    #'vect__min_df': (.005, .01, .015),\n",
    "    #'vect__max_features': (10000, 12000),\n",
    "    #'clf__max_depth':(130,140),\n",
    "    #'clf__n_estimators':(375,450)\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "ph1NLDHWNzsT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7440678386085802"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__stop_words': {'',\n",
       "  ' ',\n",
       "  \"'d\",\n",
       "  \"'ll\",\n",
       "  \"'m\",\n",
       "  \"'re\",\n",
       "  \"'s\",\n",
       "  \"'ve\",\n",
       "  ',',\n",
       "  'a',\n",
       "  'about',\n",
       "  'above',\n",
       "  'across',\n",
       "  'after',\n",
       "  'afterwards',\n",
       "  'again',\n",
       "  'against',\n",
       "  'all',\n",
       "  'almost',\n",
       "  'alone',\n",
       "  'along',\n",
       "  'already',\n",
       "  'also',\n",
       "  'although',\n",
       "  'always',\n",
       "  'am',\n",
       "  'among',\n",
       "  'amongst',\n",
       "  'amount',\n",
       "  'an',\n",
       "  'and',\n",
       "  'another',\n",
       "  'any',\n",
       "  'anyhow',\n",
       "  'anyone',\n",
       "  'anything',\n",
       "  'anyway',\n",
       "  'anywhere',\n",
       "  'are',\n",
       "  'around',\n",
       "  'as',\n",
       "  'at',\n",
       "  'back',\n",
       "  'be',\n",
       "  'became',\n",
       "  'because',\n",
       "  'become',\n",
       "  'becomes',\n",
       "  'becoming',\n",
       "  'been',\n",
       "  'before',\n",
       "  'beforehand',\n",
       "  'behind',\n",
       "  'being',\n",
       "  'below',\n",
       "  'beside',\n",
       "  'besides',\n",
       "  'between',\n",
       "  'beyond',\n",
       "  'both',\n",
       "  'bottom',\n",
       "  'but',\n",
       "  'by',\n",
       "  'ca',\n",
       "  'call',\n",
       "  'can',\n",
       "  'cannot',\n",
       "  'could',\n",
       "  'd',\n",
       "  'did',\n",
       "  'do',\n",
       "  'doe',\n",
       "  'does',\n",
       "  'doing',\n",
       "  'done',\n",
       "  'down',\n",
       "  'due',\n",
       "  'during',\n",
       "  'each',\n",
       "  'eight',\n",
       "  'either',\n",
       "  'eleven',\n",
       "  'else',\n",
       "  'elsewhere',\n",
       "  'empty',\n",
       "  'enough',\n",
       "  'even',\n",
       "  'ever',\n",
       "  'every',\n",
       "  'everyone',\n",
       "  'everything',\n",
       "  'everywhere',\n",
       "  'except',\n",
       "  'few',\n",
       "  'fifteen',\n",
       "  'fifty',\n",
       "  'first',\n",
       "  'five',\n",
       "  'for',\n",
       "  'former',\n",
       "  'formerly',\n",
       "  'forty',\n",
       "  'four',\n",
       "  'from',\n",
       "  'front',\n",
       "  'full',\n",
       "  'further',\n",
       "  'get',\n",
       "  'give',\n",
       "  'go',\n",
       "  'ha',\n",
       "  'had',\n",
       "  'has',\n",
       "  'have',\n",
       "  'he',\n",
       "  'hence',\n",
       "  'her',\n",
       "  'here',\n",
       "  'hereafter',\n",
       "  'hereby',\n",
       "  'herein',\n",
       "  'hereupon',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'him',\n",
       "  'himself',\n",
       "  'his',\n",
       "  'how',\n",
       "  'however',\n",
       "  'hundred',\n",
       "  'i',\n",
       "  'if',\n",
       "  'in',\n",
       "  'indeed',\n",
       "  'into',\n",
       "  'is',\n",
       "  'it',\n",
       "  'its',\n",
       "  'itself',\n",
       "  'just',\n",
       "  'keep',\n",
       "  'last',\n",
       "  'latter',\n",
       "  'latterly',\n",
       "  'le',\n",
       "  'least',\n",
       "  'less',\n",
       "  'll',\n",
       "  'm',\n",
       "  'made',\n",
       "  'make',\n",
       "  'many',\n",
       "  'may',\n",
       "  'me',\n",
       "  'meanwhile',\n",
       "  'might',\n",
       "  'mine',\n",
       "  'more',\n",
       "  'moreover',\n",
       "  'most',\n",
       "  'mostly',\n",
       "  'move',\n",
       "  'much',\n",
       "  'must',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'n',\n",
       "  \"n't\",\n",
       "  'name',\n",
       "  'namely',\n",
       "  'neither',\n",
       "  'never',\n",
       "  'nevertheless',\n",
       "  'next',\n",
       "  'nine',\n",
       "  'no',\n",
       "  'nobody',\n",
       "  'none',\n",
       "  'noone',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'nothing',\n",
       "  'now',\n",
       "  'nowhere',\n",
       "  'n‘t',\n",
       "  'n’t',\n",
       "  'of',\n",
       "  'off',\n",
       "  'often',\n",
       "  'on',\n",
       "  'once',\n",
       "  'one',\n",
       "  'only',\n",
       "  'onto',\n",
       "  'or',\n",
       "  'other',\n",
       "  'others',\n",
       "  'otherwise',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'out',\n",
       "  'over',\n",
       "  'own',\n",
       "  'part',\n",
       "  'per',\n",
       "  'perhaps',\n",
       "  'please',\n",
       "  'put',\n",
       "  'quite',\n",
       "  'rather',\n",
       "  're',\n",
       "  'really',\n",
       "  'regarding',\n",
       "  's',\n",
       "  'same',\n",
       "  'say',\n",
       "  'see',\n",
       "  'seem',\n",
       "  'seemed',\n",
       "  'seeming',\n",
       "  'seems',\n",
       "  'serious',\n",
       "  'several',\n",
       "  'she',\n",
       "  'should',\n",
       "  'show',\n",
       "  'side',\n",
       "  'since',\n",
       "  'six',\n",
       "  'sixty',\n",
       "  'so',\n",
       "  'some',\n",
       "  'somehow',\n",
       "  'someone',\n",
       "  'something',\n",
       "  'sometime',\n",
       "  'sometimes',\n",
       "  'somewhere',\n",
       "  'still',\n",
       "  'such',\n",
       "  't',\n",
       "  'take',\n",
       "  'ten',\n",
       "  'than',\n",
       "  'that',\n",
       "  'the',\n",
       "  'their',\n",
       "  'them',\n",
       "  'themselves',\n",
       "  'then',\n",
       "  'thence',\n",
       "  'there',\n",
       "  'thereafter',\n",
       "  'thereby',\n",
       "  'therefore',\n",
       "  'therein',\n",
       "  'thereupon',\n",
       "  'these',\n",
       "  'they',\n",
       "  'third',\n",
       "  'this',\n",
       "  'those',\n",
       "  'though',\n",
       "  'three',\n",
       "  'through',\n",
       "  'throughout',\n",
       "  'thru',\n",
       "  'thus',\n",
       "  'to',\n",
       "  'together',\n",
       "  'too',\n",
       "  'top',\n",
       "  'toward',\n",
       "  'towards',\n",
       "  'twelve',\n",
       "  'twenty',\n",
       "  'two',\n",
       "  'u',\n",
       "  'under',\n",
       "  'unless',\n",
       "  'until',\n",
       "  'up',\n",
       "  'upon',\n",
       "  'us',\n",
       "  'used',\n",
       "  'using',\n",
       "  'various',\n",
       "  've',\n",
       "  'very',\n",
       "  'via',\n",
       "  'wa',\n",
       "  'was',\n",
       "  'we',\n",
       "  'well',\n",
       "  'were',\n",
       "  'what',\n",
       "  'whatever',\n",
       "  'when',\n",
       "  'whence',\n",
       "  'whenever',\n",
       "  'where',\n",
       "  'whereafter',\n",
       "  'whereas',\n",
       "  'whereby',\n",
       "  'wherein',\n",
       "  'whereupon',\n",
       "  'wherever',\n",
       "  'whether',\n",
       "  'which',\n",
       "  'while',\n",
       "  'whither',\n",
       "  'who',\n",
       "  'whoever',\n",
       "  'whole',\n",
       "  'whom',\n",
       "  'whose',\n",
       "  'why',\n",
       "  'will',\n",
       "  'with',\n",
       "  'within',\n",
       "  'without',\n",
       "  'would',\n",
       "  'yet',\n",
       "  'you',\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  '‘',\n",
       "  '‘d',\n",
       "  '‘ll',\n",
       "  '‘m',\n",
       "  '‘re',\n",
       "  '‘s',\n",
       "  '‘ve',\n",
       "  '’',\n",
       "  '’ s',\n",
       "  '’d',\n",
       "  '’ll',\n",
       "  '’m',\n",
       "  '’re',\n",
       "  '’s',\n",
       "  '’ve'},\n",
       " 'vect__tokenizer': <function __main__.tokenize(doc)>}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.tokenize(doc)>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "3cq-9ls5OZd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "-sOQYn_qObzp"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "lcD2DCyFOdVh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "9epcq54SOfAK"
   },
   "outputs": [],
   "source": [
    "subNumber = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "hr9POK4TOgux"
   },
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Other Algo\n",
    "svd = TruncatedSVD(n_components=100,\n",
    "                  algorithm='randomized',\n",
    "                  n_iter=10)\n",
    "\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['ratingCategory']\n",
    "features = train.drop(columns=['ratingCategory', 'id'])\n",
    "features = train['description']\n",
    "#features = pd.concat([train['sentiment_subjectivity'],pd.DataFrame(vect.fit_transform(train['description']).todense())],axis=1)\n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df': (0.9, 1.0),\n",
    "    'clf__max_depth':(5,10)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "pipe2 = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter vect for estimator Pipeline(steps=[('lsi',\n                 Pipeline(steps=[('vect',\n                                  TfidfVectorizer(ngram_range=(1, 2),\n                                                  stop_words={'', ' ', \"'d\",\n                                                              \"'ll\", \"'m\",\n                                                              \"'re\", \"'s\",\n                                                              \"'ve\", ',', 'a',\n                                                              'about', 'above',\n                                                              'across', 'after',\n                                                              'afterwards',\n                                                              'again',\n                                                              'against', 'all',\n                                                              'almost', 'alone',\n                                                              'along',\n                                                              'already', 'also',\n                                                              'although',\n                                                              'always', 'am',\n                                                              'among',\n                                                              'amongst',\n                                                              'amount', 'an', ...},\n                                                  tokenizer=<function tokenize at 0x000001E0B9256C10>)),\n                                 ('svd',\n                                  TruncatedSVD(n_components=100, n_iter=10))])),\n                ('clf', RandomForestClassifier())]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 520, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\pipeline.py\", line 141, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 53, in _set_params\n    super().set_params(**params)\n  File \"C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 249, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter vect for estimator Pipeline(steps=[('lsi',\n                 Pipeline(steps=[('vect',\n                                  TfidfVectorizer(ngram_range=(1, 2),\n                                                  stop_words={'', ' ', \"'d\",\n                                                              \"'ll\", \"'m\",\n                                                              \"'re\", \"'s\",\n                                                              \"'ve\", ',', 'a',\n                                                              'about', 'above',\n                                                              'across', 'after',\n                                                              'afterwards',\n                                                              'again',\n                                                              'against', 'all',\n                                                              'almost', 'alone',\n                                                              'along',\n                                                              'already', 'also',\n                                                              'although',\n                                                              'always', 'am',\n                                                              'among',\n                                                              'amongst',\n                                                              'amount', 'an', ...},\n                                                  tokenizer=<function tokenize at 0x000001E0B9256C10>)),\n                                 ('svd',\n                                  TruncatedSVD(n_components=100, n_iter=10))])),\n                ('clf', RandomForestClassifier())]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-f9911c342183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter vect for estimator Pipeline(steps=[('lsi',\n                 Pipeline(steps=[('vect',\n                                  TfidfVectorizer(ngram_range=(1, 2),\n                                                  stop_words={'', ' ', \"'d\",\n                                                              \"'ll\", \"'m\",\n                                                              \"'re\", \"'s\",\n                                                              \"'ve\", ',', 'a',\n                                                              'about', 'above',\n                                                              'across', 'after',\n                                                              'afterwards',\n                                                              'again',\n                                                              'against', 'all',\n                                                              'almost', 'alone',\n                                                              'along',\n                                                              'already', 'also',\n                                                              'although',\n                                                              'always', 'am',\n                                                              'among',\n                                                              'amongst',\n                                                              'amount', 'an', ...},\n                                                  tokenizer=<function tokenize at 0x000001E0B9256C10>)),\n                                 ('svd',\n                                  TruncatedSVD(n_components=100, n_iter=10))])),\n                ('clf', RandomForestClassifier())]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe2,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-99e6964859a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Unit 4 Kaggle Competition Text Blob.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
